.. _06_Stats_Running_1stLevel_Analysis.rst

To put this in mathematical terms, each voxel has a time series, which we’ll notate as Y. We also have our two regressors, which we’ll notate as x1 and x2. These regressors constitute our design matrix, which we’ll notate with a large X. So far, all of these variables are known - Y is measured from the data, and x1 and x2 are constructed from convolving the HRF and the timing onsets. Now, since the next part gets into matrix algebra, I’m going to switch the orientation of these timecourses: Normally we think of think of them as running from left to right, but now we’re going to depict them as going from top to bottom. 

The next part of this equation is the beta weights, which we’ll notate as B1 and B2, corresponding to the x1 and x2 regressors. These represent the amount that the HRF needs to be scaled to best match the original data in Y, and these weights are estimated - hence the name “beta weights”. The last term in this equation is E, which represents the residuals, or the difference between our ideal time series model and the data after estimating the beta weights. This GLM can be expanded to include many regressors, but however many there are, the GLM assumes that the data can be modeled as a linear combination of each of the regressors - hence the name General Linear Model.
